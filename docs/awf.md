## AWF Land Use and Land Cover Mapping

OlmoEarth-v1-FT-AWF-Base is a model fine-tuned from OlmoEarth-v1-Base for predicting land use and land cover type in southern Kenya using Sentinel-2 satellite images.

Here are relevant links for fine-tuning and applying the model per the documentation in
[the main README](../README.md):

- Model checkpoint: https://huggingface.co/allenai/OlmoEarth-v1-FT-AWF-Base/blob/main/model.ckpt
- Annotation GeoJSONs: https://huggingface.co/datasets/allenai/olmoearth_projects_awf/tree/main
- rslearn dataset: https://huggingface.co/datasets/allenai/olmoearth_projects_awf/blob/main/dataset.tar

## Model Details

The model inputs twelve timesteps of satellite image data, one [Sentinel-2 L2A](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a) mosaic per 30-day period.

The model is trained to predict land use and land cover type for every pixel within each 16x16 input patches.

The model achieves 90.4% overall accuracy on the validation set. The table below summarizes our experiments with different window sizes, patch sizes, and input modalities. Overall, models using Sentinel-2 only perform better.

| Window Size | Patch Size | Modalities | Accuracy (%) |
|--------------|-------------|-------------|---------------|
| 16×16 | 1 | Sentinel-2 | 90.4 |
| 16×16 | 1 | Sentinel-2 + Sentinel-1 | 83.1 |
| 16×16 | 4 | Sentinel-2 | 89.5 |
| 16×16 | 4 | Sentinel-2 + Sentinel-1 | 83.1 |
| 32×32 | 4 | Sentinel-2 | 88.5 |
| 32×32 | 4 | Sentinel-2 + Sentinel-1 | 83.1 |

## Training Data

The model is trained on point labels generated by [African Wildlife Foundation](https://www.awf.org/). There're in total 1469 labeled points across 9 categories: agriculture/settlement, grassland/barren, shrubland/savanna, herbaceous wetland, lava forest, montane forest, woodland forest (>40% canopy), urban/dense development, and open water. The AWF team used Planet imagery as the main reference to annotate these points.

Each sample include its longitude, latitude, time range (2023-01 to 2023-12), and land use /land cover type. For each sample, we generate an rslearn window centered on the location, covering one year of data. We use rslearn to obtain twelve Sentinel-2 and Sentinel-1 imagery during that time range, with one per 30-day period.

The dataset is split spatially into training (75%) and validation (25%) sets, based on a 128×128-pixel grid hashed into the two splits.

## Inference

Inference is documented in [the main README](../README.md). The prediction request geometry should have start and end timestamps that covers one year, ideally from 2023-01-01 to 2023-12-31 to match the training data. Inference runs on all 1024×1024 grid cells intersecting the geometry, using satellite images from the specified time range.

## Fine-tuning

Fine-tuning is documented in [the main README](../README.md).